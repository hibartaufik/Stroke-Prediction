#mengecek akurasi model machine learning yang telah dibuat dengan data test
score_1 = model_dt.score(X_test, y_test)
score_2 = model_dt_pure.score(X_test, y_test)

print(f"Akurasi Model 1: {round(score_1 * 100, 2)}%")
print(f"Akurasi Model 2: {round(score_2 * 100, 2)}%")

#melakukan pengecekan akurasi lebih lanjut dengan confusion matrix

#lakukan pada model dari data yang di seimbangkan
plt.style.use('ggplot')
fg, ax = plt.subplots(figsize=(12, 6))
mx1 = confusion_matrix(y_test, model_dt.predict(X_test))
sns.heatmap(mx1, cmap='Reds', annot=True, linewidths=2)
plt.title("PENGECEKAN CONFUSION MATRIX", pad=20, fontsize=20, fontweight='bold')
plt.show()

#lakukan pada model dari data yang tidak di seimbangkan
plt.style.use('ggplot')
fg, ax = plt.subplots(figsize=(12, 6))
mx2 = confusion_matrix(y_test, model_dt_pure.predict(X_test))
sns.heatmap(mx2, cmap='Reds', annot=True, linewidths=2)
plt.title("PENGECEKAN CONFUSION MATRIX", pad=20, fontsize=20, fontweight='bold')
plt.show()

#Pengecekan confusion matrix dapat menunjukkan 
#perbandingan jumlah TRUE POSITIF, TRUE NEGATIF, FALSE POSITIF, dan FALSE NEGATIF
#berdasarkan studi kasus yang dibahas, model yang memprediksi lebih banyak pasien yang stroke (TRUE POSITIF)
#lebih baik karena artinya dapat memprediksi kecenderungan pasien yang berpotensi mengidap stroke 

#berdasarkan visualisasi sebelumnya dapat dilihat presentase-nya
print("Model dengan data yang diseimbangkan")
print(f"TRUE POSITIF: {round(mx1[0][0] / (mx1[0][0] + mx1[0][1]) * 100, 2)}%")
print(f"TRUE NEGATIF: {round(mx1[1][1] / (mx1[1][1] + mx1[1][0]) * 100, 2)}%")
print("Model dengan data yang tidak diseimbangkan")
print(f"TRUE POSITIF: {round(mx2[0][0] / (mx2[0][0] + mx2[0][1]) * 100, 2)}%")
print(f"TRUE NEGATIF: {round(mx2[1][1] / (mx2[1][1] + mx2[1][0]) * 100, 2)}%")

#buat model baru dengan 100% data

#model dengan data yang diseimbangkan
new_model = DecisionTreeClassifier().fit(X, y)
new_model_pure = DecisionTreeClassifier().fit(X_pure, y_pure)
